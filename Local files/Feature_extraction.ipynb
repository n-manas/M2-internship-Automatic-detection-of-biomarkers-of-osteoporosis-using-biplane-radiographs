{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadbda8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T11:17:03.812759Z",
     "start_time": "2022-03-29T11:16:58.638450Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# ... import files\n",
    "from sys import stdout, argv\n",
    "from time import *\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "import os\n",
    "import scipy.stats\n",
    "import random\n",
    "import SimpleITK as sitk\n",
    "import pydicom\n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "import cv2  \n",
    "from PIL import Image\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n",
    "import logging\n",
    "import pywt\n",
    "from matplotlib import pyplot as plt\n",
    "from pywt._doc_utils import wavedec2_keys, draw_2d_wp_basis\n",
    "from skimage.feature import peak_local_max\n",
    "import pandas as pd\n",
    "\n",
    "#startTime = clock()\n",
    "#ctime1    = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fa30b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T11:17:13.371638Z",
     "start_time": "2022-03-29T11:17:13.270771Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Path acquisition for \"in vitro\" (DRR)\n",
    "# Define paths\n",
    "root_path = os.getcwd().replace(\"\\\\\", \"/\") + \"/In_vitro/\"\n",
    "print(root_path)\n",
    "out_path = os.getcwd().replace(\"\\\\\", \"/\") + \"/Processing/CT/\"\n",
    "print(out_path)\n",
    "\n",
    "profile_paths = []\n",
    "face_paths = []\n",
    "patients = []\n",
    "# Store file paths\n",
    "for subdir, dirs, files in os.walk(root_path):\n",
    "    dirs[:] = [d for d in dirs if d not in ['Incomplete']]\n",
    "    for direct in dirs:\n",
    "        if (\"PA\" in direct) and (\"PA18043\" not in direct) and (\"PA18044\" not in direct) and (\"PA18045\" not in direct) and (\"PA18046\" not in direct) and (\"PA18047\" not in direct) and (\"PA18048\" not in direct) and (\"PA20013\" not in direct) and (\"PA20014\" not in direct) and (\"PA17015\" not in direct) and (\"PA17033\" not in direct) and (\"PA17039\" not in direct) and (\"PA17040\" not in direct):# and (\"PA20007\" not in direct) and (\"PA20009\" not in direct) and (\"PA20010\" not in direct) ||| (\"PA14\" in direct) or (\"PA17007\" in direct) or (\"PA17009\" in direct) or (\"PA17010\" in direct) or (\"PA17013\" in direct) or (\"PA17014\" in direct):\n",
    "            patients.append(direct)\n",
    "\n",
    "face_paths =[]; profile_paths = []\n",
    "profile_L1_paths = []; profile_L2_paths = []; profile_L3_paths = []; profile_L4_paths = []\n",
    "\n",
    "face_L1_paths = []; face_L2_paths = []; face_L3_paths = []; face_L4_paths = []\n",
    "for patient in patients:\n",
    "    directory = root_path + str(patient) + \"/DRR/\"\n",
    "    if (patient == \"PA17007\") or  (patient == \"PA17009\") or (patient == \"PA17010\") or (patient == \"PA17013\") or (patient == \"PA17014\") :\n",
    "        path = directory + \"face_DRR_L1_sans_TM_ref.dcm\"\n",
    "        if os.path.exists(path):\n",
    "            face_paths.append(path)\n",
    "        path = directory + \"profil_DRR_L1_sans_TM_ref.dcm\"\n",
    "        if os.path.exists(path):\n",
    "            profile_paths.append(path)\n",
    "    else:\n",
    "        path = directory + \"face_DRR_L1_ref.dcm\"\n",
    "        if os.path.exists(path):\n",
    "            face_paths.append(path)    \n",
    "        path = directory + \"profil_DRR_L1_ref.dcm\"\n",
    "        if os.path.exists(path):\n",
    "            profile_paths.append(path)\n",
    "    path = directory + \"masque_ap_L1.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        face_L1_paths.append(path)\n",
    "    else: face_L1_paths.append(\" \")\n",
    "    path = directory + \"masque_ap_L2.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        face_L2_paths.append(path)\n",
    "    else: face_L2_paths.append(\" \")\n",
    "    path = directory + \"masque_ap_L3.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        face_L3_paths.append(path)\n",
    "    else: face_L3_paths.append(\" \")\n",
    "    path = directory + \"masque_ap_L4.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        face_L4_paths.append(path)\n",
    "    else: face_L4_paths.append(\" \")\n",
    "    path = directory + \"masque_lat_L1.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L1_paths.append(path)\n",
    "    else: profile_L1_paths.append(\" \")\n",
    "    path = directory + \"masque_lat_L2.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L2_paths.append(path)\n",
    "    else: profile_L2_paths.append(\" \")\n",
    "    path = directory + \"masque_lat_L3.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L3_paths.append(path)\n",
    "    else: profile_L3_paths.append(\" \")\n",
    "    path = directory + \"masque_lat_L4.tiff\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L4_paths.append(path)\n",
    "    else: profile_L4_paths.append(\" \")\n",
    "    #Create processing directories\n",
    "    if not os.path.exists(out_path + patient):\n",
    "            os.makedirs(out_path + patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e92eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T11:17:28.382085Z",
     "start_time": "2022-03-29T11:17:25.866142Z"
    }
   },
   "outputs": [],
   "source": [
    "## Extract Dicom images\n",
    "face_images = []\n",
    "profile_images = []\n",
    "print(len(face_paths))\n",
    "print(len(profile_paths))\n",
    "for i in range(0,len(face_paths)):\n",
    "    # specify your image path\n",
    "    face_path = face_paths[i]\n",
    "    profile_path = profile_paths[i]\n",
    "    # read dicom image\n",
    "    face_image = pydicom.dcmread(face_path)\n",
    "    profile_image = pydicom.dcmread(profile_path)\n",
    "    #convert to array\n",
    "    face_image = face_image.pixel_array\n",
    "    profile_image = profile_image.pixel_array\n",
    "    face_images.append(face_image)\n",
    "    profile_images.append(profile_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c9e33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T11:20:02.940391Z",
     "start_time": "2022-03-29T11:17:30.230484Z"
    }
   },
   "outputs": [],
   "source": [
    "## Extract ROI (biggest inner rectangle located inside trabecular bone mask) (DRR)\n",
    "## Only work with profile images\n",
    "im_face_crop_small_path = np.empty((4,len(face_paths)),dtype=np.dtype('U1000'))\n",
    "im_profile_crop_small_path = np.empty((4,len(profile_paths)),dtype=np.dtype('U1000'))\n",
    "for i in range(0,len(face_paths)):\n",
    "    im = face_images[i]\n",
    "    print(i)\n",
    "    for j in range(1,5): # number of vertebrae\n",
    "        if j == 1 and face_L1_paths[i] != \" \":\n",
    "            print(face_L1_paths[i])\n",
    "            mask = cv2.imread(face_L1_paths[i],0)\n",
    "        elif j == 2 and face_L2_paths[i] != \" \":\n",
    "            print(face_L2_paths[i])\n",
    "            mask = cv2.imread(face_L2_paths[i],0)\n",
    "        elif j == 3 and face_L3_paths[i] != \" \":\n",
    "            print(face_L3_paths[i])\n",
    "            mask = cv2.imread(face_L3_paths[i],0)\n",
    "        elif j == 4 and face_L4_paths[i] != \" \":\n",
    "            print(face_L4_paths[i])\n",
    "            mask = cv2.imread(face_L4_paths[i],0)\n",
    "        else: continue;# Select the contour\n",
    "        #plt.imshow(mask)\n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # if your mask is incurved or if you want better results, \n",
    "        # you may want to use cv2.CHAIN_APPROX_NONE instead of cv2.CHAIN_APPROX_SIMPLE, \n",
    "        # but the rectangle search will be longer\n",
    "        im_copy = im.copy()\n",
    "\n",
    "        cv2.drawContours(im_copy, contours, -1, (255,0,0), 1)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        # Get all the points of the contour\n",
    "        contour = contours[0].reshape(len(contours[0]),2)\n",
    "        # we assume a rectangle with at least two points on the contour gives a 'good enough' result\n",
    "        # get all possible rectangles based on this hypothesis\n",
    "        rect = []\n",
    "\n",
    "        for k in range(len(contour)):\n",
    "            x1, y1 = contour[k]\n",
    "            for l in range(len(contour)):\n",
    "                x2, y2 = contour[l]\n",
    "                area = abs(y2-y1)*abs(x2-x1)\n",
    "                rect.append(((x1,y1), (x2,y2), area))\n",
    "\n",
    "        # the first rect of all_rect has the biggest area, so it's the best solution if he fits in the picture\n",
    "        all_rect = sorted(rect, key = lambda x : x[2], reverse = True)\n",
    "\n",
    "        # we take the largest rectangle we've got, based on the value of the rectangle area\n",
    "        # only if the border of the rectangle is not in the black part\n",
    "        \n",
    "        # if the list is not empty\n",
    "        if all_rect:\n",
    "\n",
    "            best_rect_found = False\n",
    "            index_rect = 0\n",
    "            nb_rect = len(all_rect)\n",
    "\n",
    "            # we check if the rectangle is  a good solution\n",
    "            while not best_rect_found and index_rect < nb_rect:\n",
    "\n",
    "                rect = all_rect[index_rect]\n",
    "                (x1, y1) = rect[0]\n",
    "                (x2, y2) = rect[1]\n",
    "\n",
    "                valid_rect = True\n",
    "\n",
    "                # we search a black area in the perimeter of the rectangle (vertical borders)\n",
    "                x = min(x1, x2)\n",
    "                while x <max(x1,x2)+1 and valid_rect:\n",
    "                    if mask[y1,x] == 0 or mask[y2,x] == 0:\n",
    "                        # if we find a black pixel, that means a part of the rectangle is black\n",
    "                        # so we don't keep this rectangle\n",
    "                        valid_rect = False\n",
    "                    x+=1\n",
    "\n",
    "                y = min(y1, y2)\n",
    "                while y <max(y1,y2)+1 and valid_rect:\n",
    "                    if mask[y,x1] == 0 or mask[y,x2] == 0:\n",
    "                        valid_rect = False\n",
    "                    y+=1\n",
    "\n",
    "                if valid_rect:\n",
    "                    best_rect_found = True\n",
    "\n",
    "                index_rect+=1\n",
    "            print(best_rect_found)\n",
    "            if best_rect_found:\n",
    "\n",
    "                cv2.rectangle(im_copy, (x1,y1), (x2,y2), (255,0,0), 1)\n",
    "                #cv2.imshow(im_copy)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "                # Finally, we crop the picture and store it\n",
    "                result = im[min(y1+1, y2):max(y1+1, y2), min(x1+1,x2):max(x1+1,x2)]\n",
    "                \n",
    "                im_face_crop_small_path[j-1,i] = out_path + patients[i] + \"/face_L\" + str(j) + \"_crop_small.png\"\n",
    "                print(im_face_crop_small_path[j-1,i])\n",
    "                #cv2.imshow(result)\n",
    "                #cv2.imwrite(im_face_crop_small_path[j-1,i],result)\n",
    "                #cv2.waitKey(0)\n",
    "            else:\n",
    "                print(\"No rectangle fitting into the area\")\n",
    "\n",
    "        else:\n",
    "            print(\"No rectangle found\")\n",
    "    im = profile_images[i]\n",
    "    for j in range(1,5): # number of vertebrae\n",
    "        if j == 1 and profile_L1_paths[i] != \" \":\n",
    "            mask = cv2.imread(profile_L1_paths[i],0)\n",
    "        elif j == 2 and profile_L2_paths[i] != \" \":\n",
    "            mask = cv2.imread(profile_L2_paths[i],0)\n",
    "        elif j == 3 and profile_L3_paths[i] != \" \":\n",
    "            mask = cv2.imread(profile_L3_paths[i],0)\n",
    "        elif j == 4 and profile_L4_paths[i] != \" \":\n",
    "            mask = cv2.imread(profile_L4_paths[i],0)\n",
    "        else: continue;# Select the contour\n",
    "        #plt.imshow(mask)\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # if your mask is incurved or if you want better results, \n",
    "        # you may want to use cv2.CHAIN_APPROX_NONE instead of cv2.CHAIN_APPROX_SIMPLE, \n",
    "        # but the rectangle search will be longer\n",
    "        im_copy = im.copy()\n",
    "\n",
    "        cv2.drawContours(im_copy, contours, -1, (255,0,0), 1)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        # Get all the points of the contour\n",
    "        contour = contours[0].reshape(len(contours[0]),2)\n",
    "\n",
    "        # we assume a rectangle with at least two points on the contour gives a 'good enough' result\n",
    "        # get all possible rectangles based on this hypothesis\n",
    "        rect = []\n",
    "\n",
    "        for k in range(len(contour)):\n",
    "            x1, y1 = contour[k]\n",
    "            for l in range(len(contour)):\n",
    "                x2, y2 = contour[l]\n",
    "                area = abs(y2-y1)*abs(x2-x1)\n",
    "                rect.append(((x1,y1), (x2,y2), area))\n",
    "\n",
    "        # the first rect of all_rect has the biggest area, so it's the best solution if he fits in the picture\n",
    "        all_rect = sorted(rect, key = lambda x : x[2], reverse = True)\n",
    "\n",
    "        # we take the largest rectangle we've got, based on the value of the rectangle area\n",
    "        # only if the border of the rectangle is not in the black part\n",
    "\n",
    "        # if the list is not empty\n",
    "        if all_rect:\n",
    "\n",
    "            best_rect_found = False\n",
    "            index_rect = 0\n",
    "            nb_rect = len(all_rect)\n",
    "\n",
    "            # we check if the rectangle is  a good solution\n",
    "            while not best_rect_found and index_rect < nb_rect:\n",
    "\n",
    "                rect = all_rect[index_rect]\n",
    "                (x1, y1) = rect[0]\n",
    "                (x2, y2) = rect[1]\n",
    "\n",
    "                valid_rect = True\n",
    "\n",
    "                # we search a black area in the perimeter of the rectangle (vertical borders)\n",
    "                x = min(x1, x2)\n",
    "                while x <max(x1,x2)+1 and valid_rect:\n",
    "                    if mask[y1,x] == 0 or mask[y2,x] == 0:\n",
    "                        # if we find a black pixel, that means a part of the rectangle is black\n",
    "                        # so we don't keep this rectangle\n",
    "                        valid_rect = False\n",
    "                    x+=1\n",
    "\n",
    "                y = min(y1, y2)\n",
    "                while y <max(y1,y2)+1 and valid_rect:\n",
    "                    if mask[y,x1] == 0 or mask[y,x2] == 0:\n",
    "                        valid_rect = False\n",
    "                    y+=1\n",
    "\n",
    "                if valid_rect:\n",
    "                    best_rect_found = True\n",
    "\n",
    "                index_rect+=1\n",
    "            print(best_rect_found, flush=True)\n",
    "            cv2.waitKey(2)\n",
    "            if best_rect_found:\n",
    "\n",
    "                cv2.rectangle(im_copy, (x1,y1), (x2,y2), (255,0,0), 1)\n",
    "                #cv2.imshow(im_copy)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "                # Finally, we crop the picture and store it\n",
    "                result = im[min(y1+1, y2):max(y1+1, y2), min(x1+1,x2):max(x1+1,x2)]\n",
    "            \n",
    "                im_profile_crop_small_path[j-1,i] = out_path + patients[i] + \"/profil_L\" + str(j) + \"_crop_small.png\"\n",
    "                #cv2.imshow(result)\n",
    "                print(im_profile_crop_small_path[j-1,i], flush=True)\n",
    "                cv2.imwrite(im_profile_crop_small_path[j-1,i],result)\n",
    "                #cv2.waitKey(0)\n",
    "            else:\n",
    "                print(\"No rectangle fitting into the area\")\n",
    "\n",
    "        else:\n",
    "            print(\"No rectangle found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951f8a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T11:20:05.990369Z",
     "start_time": "2022-03-29T11:20:05.060268Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "## Equalization of histogram\n",
    "im_crop_equalized_path = np.empty((4,len(face_paths)),dtype=np.dtype('U1000'))\n",
    "im_crop_small_path = im_profile_crop_small_path\n",
    "for i in range(0,im_crop_small_path.shape[1]):\n",
    "    print(i)\n",
    "    for j in range(0,4):\n",
    "        if im_crop_small_path[j,i] == \"\": continue;\n",
    "        else:\n",
    "            im = cv2.imread(im_crop_small_path[j,i],0)\n",
    "            im_eq = exposure.equalize_hist(im)\n",
    "            im_crop_equalized_path[j,i] = out_path + patients[i] + \"/profil_L\" + str(j+1) + \"_crop_small_equalized.png\"\n",
    "            #cv2.imshow(result)\n",
    "            im_eq = cv2.convertScaleAbs(im_eq, alpha=(255.0))\n",
    "            #plt.hist(im_eq.ravel())\n",
    "            cv2.imwrite(im_crop_equalized_path[j,i],im_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (OPTIONAL) Imports for new data with csv filename\n",
    "\n",
    "## Path acquisition for \"in vitro\" (DRR)\n",
    "# Define paths\n",
    "root_path = os.getcwd().replace(\"\\\\\", \"/\") + \"/Unprocessed data/\"\n",
    "\n",
    "df = pd.read_csv(root_path + \"DRR_filenames_labels_arbitrary_simple.csv\", sep=\";\")\n",
    "file_paths = df[\"file_name\"].values\n",
    "out_path = os.getcwd().replace(\"\\\\\", \"/\") + \"/New features/\"\n",
    "\n",
    "patients = np.arange(0,48)\n",
    "profile_L1_paths = np.empty(len(patients),dtype=np.dtype('U1000'))\n",
    "profile_L2_paths = np.empty(len(patients),dtype=np.dtype('U1000'))\n",
    "profile_L3_paths = np.empty(len(patients),dtype=np.dtype('U1000'))\n",
    "profile_L4_paths = np.empty(len(patients),dtype=np.dtype('U1000'))\n",
    "k = -1\n",
    "for patient in patients:\n",
    "    k = k +1\n",
    "    if patient < 10:\n",
    "        p = \"0\" +str(patient)\n",
    "    else: p = str(patient)\n",
    "    path = root_path + p + \"_profil_L1_crop_small.png\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L1_paths[k] = path\n",
    "    else: profile_L1_paths[k] = \" \"\n",
    "    path = root_path + p + \"_profil_L2_crop_small.png\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L2_paths[k] = path\n",
    "    else: profile_L2_paths[k] = \" \"\n",
    "    path = root_path + p + \"_profil_L3_crop_small.png\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L3_paths[k] = path\n",
    "    else: profile_L3_paths[k] = \" \"\n",
    "    path = root_path + p + \"_profil_L4_crop_small.png\"\n",
    "    if os.path.exists(path):\n",
    "        profile_L4_paths[k] = path\n",
    "    else: profile_L4_paths[k] = \" \"\n",
    "\n",
    "#Creation of array with all paths        \n",
    "im_profile_crop_small_path = np.empty((4,len(patients)),dtype=np.dtype('U1000'))\n",
    "for i in range(0,len(patients)):\n",
    "    for j in range(0,4):\n",
    "        if j==0 and profile_L1_paths[i] != \" \" and profile_L1_paths[i] != \"\":\n",
    "            im_profile_crop_small_path[j,i] = profile_L1_paths[i]\n",
    "        elif j==1 and profile_L2_paths[i] != \" \" and profile_L2_paths[i] != \"\":\n",
    "            im_profile_crop_small_path[j,i] = profile_L2_paths[i]\n",
    "        elif j==2 and profile_L3_paths[i] != \" \" and profile_L3_paths[i] != \"\":\n",
    "            im_profile_crop_small_path[j,i] = profile_L3_paths[i]\n",
    "        elif j==3 and profile_L4_paths[i] != \" \" and profile_L4_paths[i] != \"\":\n",
    "            im_profile_crop_small_path[j,i] = profile_L4_paths[i]\n",
    "        else:\n",
    "            im_profile_crop_small_path[j,i] = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ab454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:51:04.021861Z",
     "start_time": "2022-03-28T08:51:00.565219Z"
    }
   },
   "outputs": [],
   "source": [
    "# computation of Fourier features\n",
    "im_crop_small_path = im_profile_crop_small_path# use im_crop_equalized_path when using the raw data\n",
    "\n",
    "df_fourier = pd.DataFrame(columns={\"id\",\"Patient\",\"Vertebrae\",\"RMS\",\"FMS\"})\n",
    "# Compute Fourier Texture Features\n",
    "def rms_flat(a):\n",
    "    \"\"\"\n",
    "    Return the root mean square of all the elements of *a*, flattened out.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(np.absolute(a)**2))\n",
    "\n",
    "\n",
    "def rms_fft(spectrum):\n",
    "    \"\"\"\n",
    "    Use Parseval's theorem to find the RMS value of a signal from its fft,\n",
    "    without wasting time doing an inverse FFT.\n",
    "    For a signal x, these should produce the same result, to within numerical\n",
    "    accuracy:\n",
    "    rms_flat(x) ~= rms_fft(fft(x))\n",
    "    \"\"\"\n",
    "    return rms_flat(spectrum)/np.sqrt(len(spectrum))\n",
    "\n",
    "rms=np.zeros((4,im_crop_small_path.shape[1]))\n",
    "fms=np.zeros((4,im_crop_small_path.shape[1]))\n",
    "for i in range(0,im_crop_small_path.shape[1]):\n",
    "    for j in range(0,4):\n",
    "        if (im_crop_small_path[j,i] == \" \") or (im_crop_small_path[j,i] == \"\"): continue;\n",
    "        else:\n",
    "            print(im_crop_small_path[j,i])\n",
    "            im = cv2.imread(im_crop_small_path[j,i],0)\n",
    "            f = np.fft.fft2(im)\n",
    "            fshift = np.fft.fftshift(f)\n",
    "            spectrum = 20*np.log(np.abs(fshift))\n",
    "            rms[j,i] = rms_fft(spectrum)\n",
    "            #print(\"RMS: \", rms[j,i])\n",
    "            fms[j,i] = np.sum(abs(spectrum)) / len(spectrum)\n",
    "            #fms = scipy.stats.moment(spectrum, 1)\n",
    "            #print(\"FMS: \", fms[j,i])\n",
    "            df2 = {'id': int(i+1),'Patient': patients[i], 'Vertebrae': \"L\" + str(j+1), 'FMS': fms[j,i], 'RMS': rms[j,i]}\n",
    "            df_fourier = df_fourier.append(df2, ignore_index = True)\n",
    "\n",
    "cols = [\"id\",\"Patient\",\"Vertebrae\",\"FMS\",\"RMS\"]\n",
    "excel_path = out_path + \"profile_fourier_features.xlsx\"\n",
    "df_fourier.to_excel(excel_path, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476d02c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T11:22:37.039131Z",
     "start_time": "2022-03-29T11:20:21.078361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cv2 import waitKey\n",
    "\n",
    "out_path = root_path + \"Processing/\"\n",
    "\n",
    "# Wavelet computation\n",
    "im_crop_small_path = im_profile_crop_small_path\n",
    "wavelets=np.zeros((4,len(patients),7))\n",
    "fms=np.zeros((4,len(patients)))\n",
    "im_wavelet_paths = np.empty((4,len(patients),7),dtype=np.dtype('U1000'))\n",
    "\n",
    "for i in range(0,im_crop_small_path.shape[1]):\n",
    "    if not os.path.exists(out_path + str(patients[i]) + \"/wavelets\"):\n",
    "            os.makedirs(out_path + str(patients[i]) + \"/wavelets\")\n",
    "    for j in range(0,4):\n",
    "        if (im_crop_small_path[j,i] == \" \") or (im_crop_small_path[j,i] == \"\"): continue;\n",
    "        else:\n",
    "            x = cv2.imread(im_crop_small_path[j,i],0)\n",
    "            shape = x.shape\n",
    "\n",
    "            max_lev = 2       # how many levels of decomposition to draw\n",
    "            label_levels = 2  # how many levels to explicitly label on the plots\n",
    "            im_wavelet_path = []\n",
    "            fig, axes = plt.subplots(2, 4, figsize=[14, 8])\n",
    "            arr3 = []\n",
    "            for level in range(max_lev, max_lev + 1):\n",
    "                if level == 0:\n",
    "                    # show the original image before decomposition\n",
    "                    axes[0, 0].set_axis_off()\n",
    "                    axes[1, 0].imshow(x, cmap=plt.cm.gray)\n",
    "                    axes[1, 0].set_title('Image')\n",
    "                    axes[1, 0].set_axis_off()\n",
    "                    continue\n",
    "\n",
    "                # plot subband boundaries of a standard DWT basis\n",
    "                draw_2d_wp_basis(shape, wavedec2_keys(level), ax=axes[0, level],\n",
    "                                 label_levels=label_levels)\n",
    "                axes[0, level].set_title('{} level\\ndecomposition'.format(level))\n",
    "\n",
    "                # compute the 2D DWT\n",
    "                c = pywt.wavedec2(x, 'db2', mode='periodization', level=level)\n",
    "                \n",
    "                # normalize each coefficient array independently for better visibility\n",
    "                c[0] /= np.abs(c[0]).max()\n",
    "                for detail_level in range(level):\n",
    "                    c[detail_level + 1] = [d/np.abs(d).max() for d in c[detail_level + 1]]\n",
    "                    \n",
    "                # show the normalized coefficients\n",
    "                arr, slices = pywt.coeffs_to_array(c)\n",
    "                axes[1, level].imshow(arr, cmap=plt.cm.gray)\n",
    "                axes[1, level].set_title('Coefficients\\n({} level)'.format(level))\n",
    "                axes[1, level].set_axis_off()\n",
    "                arr2, slices = pywt.coeffs_to_array(c)\n",
    "                arr3.append(arr2[slices[0]]*255)\n",
    "                arr3.append(arr2[slices[1]['ad']]*255)\n",
    "                arr3.append(arr2[slices[1]['da']]*255)\n",
    "                arr3.append(arr2[slices[1]['dd']]*255)\n",
    "                if level == 2:\n",
    "                  arr3.append(arr2[slices[2]['ad']]*255)\n",
    "                  arr3.append(arr2[slices[2]['da']]*255)\n",
    "                  arr3.append(arr2[slices[2]['dd']]*255)\n",
    "                \n",
    "                for k in range(0, 7):\n",
    "                    im_wavelet_paths[j,i,k] = out_path + str(patients[i]) + \"/wavelets/profile_L\" + str(j) + \"_im_wavelet_level_\" + str(level) +\"_pos_\"+ str(k) + \"_eq.png\"\n",
    "                    #sitk.WriteImage(arr3[k], im_wavelet_paths[j,i,k])\n",
    "                    #save wavelet images\n",
    "                    cv2.imwrite(im_wavelet_paths[j,i,k],arr3[k])\n",
    "                    #waitKey(0)\n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d31712",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T11:25:34.955Z"
    }
   },
   "outputs": [],
   "source": [
    "## Wavelet features computation (GLCM, GLDM, GLRLM & GLSZM )\n",
    "\n",
    "wavelet_feature_vector = np.zeros((4,len(patients),7))\n",
    "mask_paths = np.empty((4,len(patients),7),dtype=np.dtype('U1000'))\n",
    "l=-1\n",
    "\n",
    "# Important, run once commenting these first few lines containing df_test first, then uncomment them and run again\n",
    "# this is to obtain the column names of all the features\n",
    "# code will be interrupted because of df_test not existing in the loop on the first run (this is okay)\n",
    "df_test = df[0:0]\n",
    "df_test[\"Wavelet\"] = \"\"\n",
    "df_test[\"Vertebrae\"] = \"\"\n",
    "df_test[\"Patient\"] = \"\"\n",
    "df_test[\"index\"] = \"\"\n",
    "df_test.set_index(\"index\")\n",
    "cols = df_test.columns\n",
    "cols = cols[-4:].append(cols[:-4])\n",
    "df_test = df_test[cols]\n",
    "\n",
    "for i in range(0,im_wavelet_paths.shape[1]):\n",
    "    l = l +1\n",
    "    if not os.path.exists(out_path + str(patients[i]) + \"/wavelets/masks\"):\n",
    "            os.makedirs(out_path + str(patients[i]) + \"/wavelets/masks\")\n",
    "    for j in range(0,im_wavelet_paths.shape[0]):\n",
    "        if (im_crop_small_path[j,i] == \" \") or (im_crop_small_path[j,i] == \"\"): continue;\n",
    "        else:\n",
    "            for k in range(0,im_wavelet_paths.shape[2]):\n",
    "                imageName = im_wavelet_paths[j,i,k]\n",
    "                im = cv2.imread(imageName,0)\n",
    "                mask = np.zeros((int(im.shape[0]),int(im.shape[1])))\n",
    "                mask[1:-1,1:-1] = 1\n",
    "                #plt.imshow(mask)\n",
    "                mask_paths[j,i,k] = out_path + str(patients[i]) + \"/wavelets/masks/L\" + str(j+1) + \"_mask_wavelet_\" + str(k) + \"_eq.png\"\n",
    "                maskName = mask_paths[j,i,k]\n",
    "                cv2.imwrite(mask_paths[j,i,k],mask)\n",
    "\n",
    "                if imageName is None or maskName is None:  # Something went wrong, in this case PyRadiomics will also log an error\n",
    "                    print('Error getting testcase!')\n",
    "                    exit()\n",
    "\n",
    "                # Regulate verbosity with radiomics.verbosity (default verbosity level = WARNING)\n",
    "                radiomics.setVerbosity(logging.INFO)\n",
    "\n",
    "                # Get the PyRadiomics logger (default log-level = INFO)\n",
    "                logger = radiomics.logger\n",
    "                logger.setLevel(logging.INFO)\n",
    "                logger.setLevel(logging.DEBUG)  # set level to DEBUG to include debug log messages in log file\n",
    "\n",
    "                # Set up the handler to write out all log entries to a file\n",
    "                handler = logging.FileHandler(filename='testLog.txt', mode='w')\n",
    "                formatter = logging.Formatter(\"%(levelname)s:%(name)s: %(message)s\")\n",
    "                handler.setFormatter(formatter)\n",
    "                logger.addHandler(handler)\n",
    "\n",
    "                # Define settings for signature calculation\n",
    "                # These are currently set equal to the respective default values\n",
    "                settings = {}\n",
    "                settings['binWidth'] = 25\n",
    "                settings['resampledPixelSpacing'] = None  # [3,3,3] is an example for defining resampling (voxels with size 3x3x3mm)\n",
    "                settings['interpolator'] = sitk.sitkBSpline\n",
    "\n",
    "                # Initialize feature extractor\n",
    "                extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "                # By default, only original is enabled. Optionally enable some image types:\n",
    "                extractor.enableImageTypes(Original={}, LoG={}, Wavelet={})\n",
    "\n",
    "                # Disable all classes except firstorder\n",
    "                #extractor.disableAllFeatures()\n",
    "\n",
    "                # Enable all features in firstorder\n",
    "                # extractor.enableFeatureClassByName('firstorder')\n",
    "\n",
    "                # Only enable mean and skewness in firstorder\n",
    "                #extractor.enableFeaturesByName(firstorder=['Mean', 'Skewness'])\n",
    "                #print(\"Calculating features\", l)\n",
    "                result = extractor.execute(str(imageName),str(maskName))\n",
    "                result.pop(\"diagnostics_Versions_PyRadiomics\")\n",
    "                result.pop(\"diagnostics_Versions_Numpy\")\n",
    "                result.pop(\"diagnostics_Versions_SimpleITK\")\n",
    "                result.pop(\"diagnostics_Versions_PyWavelet\")\n",
    "                result.pop(\"diagnostics_Versions_Python\")\n",
    "                result.pop(\"diagnostics_Configuration_Settings\")\n",
    "                result.pop(\"diagnostics_Configuration_EnabledImageTypes\")\n",
    "                result.pop(\"diagnostics_Image-original_Hash\")\n",
    "                result.pop(\"diagnostics_Image-original_Dimensionality\")\n",
    "                result.pop(\"diagnostics_Image-original_Spacing\")\n",
    "                result.pop(\"diagnostics_Image-original_Size\")\n",
    "                result.pop(\"diagnostics_Mask-original_Hash\")\n",
    "                result.pop(\"diagnostics_Mask-original_Size\")\n",
    "                result.pop(\"diagnostics_Mask-original_Spacing\")\n",
    "                result.pop(\"diagnostics_Mask-original_BoundingBox\")\n",
    "                result.pop(\"diagnostics_Mask-original_VoxelNum\")\n",
    "                result.pop(\"diagnostics_Mask-original_VolumeNum\")\n",
    "                result.pop(\"diagnostics_Mask-original_CenterOfMassIndex\")\n",
    "                result.pop(\"diagnostics_Mask-original_CenterOfMass\")\n",
    "                #for featureName in result.keys():\n",
    "                #    print(\"Computed %s: %s\" % (featureName, result[featureName]))\n",
    "                df = pd.DataFrame.from_dict(data=result, orient='index')\n",
    "                df = df.T\n",
    "                df[\"index\"] = l\n",
    "                df.set_index(\"index\")\n",
    "                df[\"Patient\"] = str(patients[i])\n",
    "                df[\"Vertebrae\"] = \"L\" + str(j)\n",
    "                df[\"Wavelet\"] = str(k)\n",
    "                df_test = pd.concat([df_test,df])\n",
    "excel_path = out_path + \"profile_wavelet_features.xlsx\"\n",
    "df_test.to_excel(excel_path,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d406d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:59:19.791630Z",
     "start_time": "2022-03-28T08:58:18.070211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute vertebral heights, wall lengths, plate angles for a vertain vertebral type \n",
    "# this version of the code only works with the raw data since it requires the non-cropped DRR images\n",
    "# This cell needs to be rerun for each type of vertebra\n",
    "\n",
    "\"\"\"\n",
    "Task: Detect corners and fix perspective\n",
    "Source: https://stackoverflow.com/questions/64860785/opencv-using-canny-and-shi-tomasi-to-detect-round-corners-of-a-playing-card\n",
    "\"\"\"\n",
    "\n",
    "def dist(p, q):\n",
    "    #Return the Euclidean distance between points p and q.\n",
    "    return math.hypot(p[0] - q[0], p[1] - q[1])\n",
    "        \n",
    "def horizontal_angle(p1,p2):\n",
    "    xDiff = p2[0] - p1[0]\n",
    "    yDiff = p2[1] - p1[1]\n",
    "    return math.degrees(math.atan2(yDiff, xDiff))\n",
    "\n",
    "anterior_heights = np.zeros(len(profile_L1_paths))\n",
    "posterior_heights = np.zeros(len(profile_L1_paths))\n",
    "length_top = np.zeros(len(profile_L1_paths))\n",
    "length_left = np.zeros(len(profile_L1_paths))\n",
    "length_bottom = np.zeros(len(profile_L1_paths))\n",
    "length_right = np.zeros(len(profile_L1_paths))\n",
    "top_plate_angles = np.zeros(len(profile_L1_paths))\n",
    "bottom_plate_angles = np.zeros(len(profile_L1_paths))\n",
    "\n",
    "for k in range(0,len(profile_L1_paths)):\n",
    "    path = profile_L1_paths[k] #modify L1 to desired vertebra\n",
    "    #print(path,flush=\"True\")\n",
    "    if path != ' ':\n",
    "        mask = cv2.imread(path,0)\n",
    "        gray = np.float32(mask)\n",
    "        img = mask.astype(np.uint8)\n",
    "        img = scipy.ndimage.rotate(img, -35, cval=0)\n",
    "        gray = gray.astype(np.uint8)\n",
    "        gray = scipy.ndimage.rotate(gray, -35, cval=0)\n",
    "        # cut rectangle that fits mask\n",
    "        x,y,w,h = cv2.boundingRect(img)\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        plt.imshow(img)\n",
    "\n",
    "        M = img.shape[0]#//2\n",
    "        N = img.shape[1]#//2\n",
    "        tiles = [img[x:x+M,y:y+N] for x in range(0,img.shape[0],M) for y in range(0,img.shape[1],N)]\n",
    "        corners = np.zeros((4,2))\n",
    "\n",
    "        for i in range(0,len(tiles)):\n",
    "            im = tiles[i]\n",
    "            gray = tiles[i]\n",
    "            ret,thresh = cv2.threshold(gray,127,255,0)\n",
    "\n",
    "            #cv2.imshow('Thresholded original',thresh)\n",
    "            #cv2.waitKey(0)\n",
    "\n",
    "            ## Get contours\n",
    "            contours,h = cv2.findContours(thresh,cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            ## only draw contour that have big areas\n",
    "            imx = im.shape[0]\n",
    "            imy = im.shape[1]\n",
    "            lp_area = (imx * imy) / 10\n",
    "\n",
    "            ## Get only rectangles given exceeding area\n",
    "            for cnt in contours:\n",
    "                approx = []\n",
    "                constant = 0.01\n",
    "                while len(approx) != 4 and constant <= 1:\n",
    "                    approx = cv2.approxPolyDP(cnt,constant * cv2.arcLength(cnt, True), True)\n",
    "                    ## calculate number of vertices\n",
    "                    #print(len(approx))\n",
    "                    constant = constant + 0.01\n",
    "\n",
    "                if constant == 1: print(\"Could not approximate polygon.\")\n",
    "                else:\n",
    "                    #print(\"rectangle\")\n",
    "\n",
    "                    tmp_img = im.copy()\n",
    "                    cv2.drawContours(tmp_img, [cnt], 0, (0, 255, 255), 6)\n",
    "                    #cv2.imshow('Contour Borders', tmp_img)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "\n",
    "                    tmp_img = im.copy()\n",
    "                    cv2.drawContours(tmp_img, [cnt], 0, (255, 0, 255), -1)\n",
    "                    #cv2.imshow('Contour Filled', tmp_img)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "\n",
    "                    # Make a hull arround the contour and draw it on the original image\n",
    "                    tmp_img = im.copy()\n",
    "                    mask = np.zeros((im.shape[:2]), np.uint8)\n",
    "                    hull = cv2.convexHull(cnt)\n",
    "                    cv2.drawContours(mask, [hull], 0, (255, 255, 255), -1)\n",
    "                    #cv2.imshow('Convex Hull Mask', mask)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "\n",
    "                    # Draw minimum area rectangle\n",
    "                    tmp_img = im.copy()\n",
    "                    rect = cv2.minAreaRect(cnt)\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box = np.int0(box)\n",
    "                    cv2.drawContours(tmp_img, [box], 0, (0, 0, 255), 2)\n",
    "                    #cv2.imshow('Minimum Area Rectangle', tmp_img)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "\n",
    "                    # Draw bounding rectangle\n",
    "                    tmp_img = im.copy()\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    cv2.rectangle(tmp_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    #cv2.imshow('Bounding Rectangle', tmp_img)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "\n",
    "                    # Bounding Rectangle and Minimum Area Rectangle\n",
    "                    tmp_img = im.copy()\n",
    "                    rect = cv2.minAreaRect(cnt)\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box = np.int0(box)\n",
    "                    cv2.drawContours(tmp_img, [box], 0, (0, 0, 255), 2)\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    cv2.rectangle(tmp_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    #cv2.imshow('Bounding Rectangle', tmp_img)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "\n",
    "                    # determine the most extreme points along the contour\n",
    "                    # https://www.pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/\n",
    "                    tmp_img = im.copy()\n",
    "                    extLeft_tmp = tuple(cnt[cnt[:, :, 0].argmin()][0])\n",
    "                    extRight_tmp = tuple(cnt[cnt[:, :, 0].argmax()][0])\n",
    "                    extTop_tmp = tuple(cnt[cnt[:, :, 1].argmin()][0])\n",
    "                    extBot_tmp = tuple(cnt[cnt[:, :, 1].argmax()][0])\n",
    "                    #print(\"Corner Points: \", extLeft_tmp, extRight_tmp, extTop_tmp, extBot_tmp)\n",
    "\n",
    "                    corners[0][0] = extLeft_tmp[0]\n",
    "                    corners[0][1] = extLeft_tmp[1]\n",
    "                    corners[1][0] = extTop_tmp[0]\n",
    "                    corners[1][1] = extTop_tmp[1]\n",
    "                    corners[2][0] = extRight_tmp[0]\n",
    "                    corners[2][1] = extRight_tmp[1]\n",
    "                    corners[3][0] = extBot_tmp[0]\n",
    "                    corners[3][1] = extBot_tmp[1]\n",
    "                    cv2.circle(tmp_img, extLeft_tmp, 8, (128, 128, 128), -1)\n",
    "                    cv2.circle(tmp_img, extRight_tmp, 8, (128, 128, 0), -1)\n",
    "                    cv2.circle(tmp_img, extTop_tmp, 8, (128, 128, 128), -1)\n",
    "                    cv2.circle(tmp_img, extBot_tmp, 8, (128, 128, 128), -1)\n",
    "\n",
    "\n",
    "                    #cv2.imshow('img contour drawn', tmp_img)\n",
    "                    #cv2.waitKey(0)\n",
    "                    #cv2.destroyAllWindows()\n",
    "        tmp_img = im.copy()\n",
    "        for x,y in corners:\n",
    "            cv2.circle(tmp_img, (int(x),int(y)), 8, (128, 128, 128), -1)\n",
    "\n",
    "        plt.figure(i+1)\n",
    "        plt.imshow(tmp_img,cmap=\"gray\")\n",
    "        plt.show()\n",
    "        #axs[i].imshow(tmp_img,cmap=\"gray\")\n",
    "        #axs[i].set_axis_off()\n",
    "        #axs[i].set_title(i)\n",
    "        anterior = np.asarray([corners[0,:],corners[1,:]])\n",
    "        print(anterior)\n",
    "        posterior = np.asarray([corners[2,:],corners[3,:]])\n",
    "        print(posterior)\n",
    "        # Compute anterior and posterior distances\n",
    "        # According to EOS imaging, pixel size = 254 Î¼m --> 0.18 mm\n",
    "        \n",
    "        anterior_heights[k] = dist(anterior[0,:], anterior[1,:])*0.18\n",
    "        print(\"Anterior height (mm):\", anterior_heights[i])\n",
    "        posterior_heights[k] = dist(posterior[0,:], posterior[1,:])*0.18\n",
    "        print(\"Posterior height (mm):\", posterior_heights[i])\n",
    "        length_top[k] = dist(corners[1,:], corners[2,:])*0.18\n",
    "        length_left[k] = dist(corners[0,:], corners[1,:])*0.18\n",
    "        length_bottom[k] = dist(corners[3,:], corners[0,:])*0.18\n",
    "        length_right[k] = dist(corners[2,:], corners[3,:])*0.18\n",
    "        #cv2.destroyAllWindows()\n",
    "        top_plate_angles[k] = horizontal_angle(anterior[1,:],posterior[0,:])-35\n",
    "        bottom_plate_angles[k] = horizontal_angle(anterior[0,:],posterior[1,:])-35\n",
    "    else: continue;\n",
    "        \n",
    "df = pd.DataFrame({'Patient': patients,'Anterior Height': anterior_heights, 'Posterior Height': posterior_heights, 'Top Plate Angle': top_plate_angles, 'Bottom Plate Angle': bottom_plate_angles, 'Length Top': length_top, 'Length Right': length_right, 'Length Bottom': length_bottom, 'Length Left': length_left})\n",
    "df.to_excel(out_path + \"profile_heights_angles_lengths_L1.xlsx\") # modify name to match vertebra analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32ed23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T12:12:27.678577Z",
     "start_time": "2022-03-28T12:12:27.547924Z"
    }
   },
   "outputs": [],
   "source": [
    "# ISV calculation\n",
    "# Modified code from:\n",
    "# Maquer, Ghislain & Lu, Yongtao & Dall'Ara, Enrico & Chevalier, Yan & Krause, Matthias & Yang, Lang & Eastell, Richard & Lippuner, Kurt & Zysset, Philippe. (2017). ISV: python implementation and example. \n",
    "\n",
    "#Functions\n",
    "# ... bilinear interpolation\n",
    "def interpolation(im, x, y):\n",
    "    x   = np.asarray(x); y = np.asarray(y)\n",
    "    x1  = int(np.floor(x)); y1 = int(np.floor(y)); x2 = x1 + 1; y2 = y1 + 1 # positions around (x,y)\n",
    "    x1  = np.clip(x1, 0, im.shape[0]-1); y1 = np.clip(y1, 0, im.shape[1]-1); x2 = np.clip(x2, 0, im.shape[0]-1); y2 = np.clip(y2, 0, im.shape[1]-1); # limit interpolation to the image's pixels\n",
    "    I11 = im[ x1, y1 ]; I12 = im[ x1, y2 ]; I21 = im[ x2, y1 ]; I22 = im[ x2, y2 ] # intensity of the pixels around\n",
    "    w11 = (x2-x)*(y2-y) ; w12 = (x2-x)*(y-y1) ; w21 = (x-x1)*(y2-y) ; w22 = (x-x1)*(y-y1) # weights according to the distance of (x,y) to the pixels around\n",
    "    points = (w11*I11 + w12*I12 + w21*I21 + w22*I22) / ((x2-x1)*(y2-y1))\n",
    "    if np.isnan(points): points = 0\n",
    "    if math.isinf(points): points = 0\n",
    "    return points\n",
    "\n",
    "# ... rotate a point around another\n",
    "def rotatePoint(rotationcenter,originalpoint,angle):\n",
    "    angle         = math.radians(angle)\n",
    "    rotatingpoint = originalpoint[0]-rotationcenter[0] , originalpoint[1]-rotationcenter[1]\n",
    "    rotatingpoint = ( rotatingpoint[0]*math.cos(angle)-rotatingpoint[1]*math.sin(angle) , rotatingpoint[0]*math.sin(angle)+rotatingpoint[1]*math.cos(angle)) # rotation counter-clockwise\n",
    "    rotatingpoint = rotatingpoint[0]+rotationcenter[0] , rotatingpoint[1]+rotationcenter[1]\n",
    "    return rotatingpoint\n",
    "\n",
    "# ... isotropic semi-variogram optimized function\n",
    "def SV(P,h,neig,sampleROI):\n",
    "    stdout.write( \"     Lag %i... \\n\" %(h) ); stdout.flush()\n",
    "    u0 = np.asarray([1, 0]) # the unit vector in the direction 0 deg (horizontal)\n",
    "    a = 1\n",
    "    b = 1\n",
    "    SVar = np.zeros((neig,len(sampleROI)))\n",
    "    for theta in np.random.uniform(0.0, 360.0, size=neig):\n",
    "        # compute the semivariance of each P(i,j) and its random neighbours at distance h if they are in the ROI\n",
    "        for b in range(0,len(sampleROI)):\n",
    "            i = sampleROI[b][0]\n",
    "            j = sampleROI[b][1]\n",
    "            interp = interpolation( P, rotatePoint((i,j),(i+h*u0[0],j+h*u0[1]),theta)[0], rotatePoint((i,j),(i+h*u0[0],j+h*u0[1]),theta)[1] )\n",
    "            if interp !=0:\n",
    "                SVar[a-1][b-1] = np.mean(P[i,j]- interp)**2\n",
    "            b=b+1\n",
    "        a=a+1\n",
    "    return np.mean(SVar) # average semivariance over all possible pairs\n",
    "\n",
    "# ISV computation\n",
    "### ... parameter entry\n",
    "#Type             argId    Description                               Default           Opt.  Info \n",
    "guiInit = \"*modulName     'Initial slope of the variogram'                                                     \\n\"\\\n",
    "+\"*subWindowStart          'Initial slope of the variogram'                                                     \\n\"\\\n",
    "+\"*fileEntryIn    -in      'Input file'                               filename.mhd      no    mhd               \\n\"\\\n",
    "+\"*entry          -pix     '(%) Fraction of the region of interest'   100               yes   1                 \\n\"\\\n",
    "+\"*entry          -hmax    'Number of lags'                           6                 yes   1                 \\n\"\\\n",
    "+\"*entry          -neig    'Number of neighbours'                     36                yes   1                 \\n\"\\\n",
    "+\"*entry          -pts     'Number of points for slope computation'   5                 yes   1                 \\n\"\\\n",
    "+\"*subWindowEnd            'Initial slope of the variogram computed'                                                     \\n\"\n",
    "\n",
    "ISVs = np.zeros((4,len(profile_L1_paths)))\n",
    "rs = np.zeros((4,len(profile_L1_paths)))\n",
    "p = np.zeros(len(profile_L1_paths))\n",
    "for k in range(40,len(profile_L1_paths)):\n",
    "    p = patients[k]\n",
    "    for j in range(0,4):\n",
    "        path = im_profile_crop_small_path[j,k]\n",
    "        #print(path,flush=\"True\")\n",
    "        if path != '':\n",
    "            infile = '%s' % path #im_crop_small_path # in\n",
    "            #outfile = \"filename.pdf\" # out\n",
    "            pix = 25 # pix\n",
    "            hmax = 6 # hmax\n",
    "            #neig = 36 # neig\n",
    "            #pts = 5 # pts\n",
    "            #txt = \"filename.txt\" # txt\n",
    "            #mode = \"w\" # mode\n",
    "\n",
    "            argList = argv\n",
    "            argc = len(argList)\n",
    "\n",
    "            # ... Default values for the optional arguments\n",
    "            stdout.write( \"\\n ... any default parameters? \\n\" ); stdout.flush()\n",
    "            try: print(pix)\n",
    "            except NameError: print(\"     pix: default value 100\"); pix  = 100\n",
    "\n",
    "            try: print(hmax)\n",
    "            except NameError: print(\"     hmax: default value 6\"); hmax  = 6\n",
    "\n",
    "            try: print(neig)\n",
    "            except NameError: print(\"     neig: default value 36\"); neig = 36\n",
    "\n",
    "            try: print(pts)\n",
    "            except NameError: print(\"     pts: default value 6\"); pts  = 5\n",
    "\n",
    "            # start the code\n",
    "            # ... get name\n",
    "            path, name = os.path.split(infile)\n",
    "\n",
    "            # ... read image\n",
    "            stdout.write( \"\\n ... reading image \\n\" ); stdout.flush()\n",
    "            im      = sitk.ReadImage(infile)\n",
    "            #im = Image.fromarray(im)\n",
    "            ndim = im.GetSize()\n",
    "            print(ndim)\n",
    "            array   = sitk.GetArrayFromImage(im)\n",
    "\n",
    "            # ... compute semi-variogram\n",
    "            stdout.write( \"\\n ... building the variogram \\n\" ); stdout.flush()\n",
    "            if hmax < 6:  hmax = 6; stdout.write( \"  ! number of lags too low was set to 6 ! \\n\" ); stdout.flush()\n",
    "            if   ndim[0] == 1: P  = array[:,:,0]; # data in plane (Y, Z)\n",
    "            elif ndim[1] == 1: P  = array[:,0,:]; # data in plane (X, Z)\n",
    "            #elif ndim[2] == 1: P  = array[0,:,:]; # data in plane (X, Y)\n",
    "            else: P = array;\n",
    "            dimx      = P.shape[0]; dimy = P.shape[1]; \n",
    "            pixROI    = [(i,j) for i in range(dimx) for j in range(dimy) if P[i,j]!=0]\n",
    "            sampleROI = random.sample(pixROI, int(len(pixROI)*pix/100.0)) \n",
    "            hs = np.asarray( np.arange(1,hmax+1) ) # lags\n",
    "            stdout.write( \"     %i pixels in the image \\n\" %(ndim[0]*ndim[1]) ); stdout.flush()\n",
    "            stdout.write( \"     %i pixels in the region of interest \\n\" %(len(pixROI)) ); stdout.flush()\n",
    "            stdout.write( \"     %i pixels randomly selected from the region of interest \\n\" %(len(sampleROI)) ); stdout.flush()\n",
    "            stdout.write( \"     %i neighbours randomly selected for each pixel \\n\" %(neig) ); stdout.flush()\n",
    "            stdout.write( \"     %i lags for the computation \\n\" %(hmax) ); stdout.flush()\n",
    "            sv = np.asarray( [SV(P,h,neig,sampleROI) for h in hs] )\n",
    "\n",
    "            # ... compute ISV\n",
    "            stdout.write( \"\\n ... computation of the ISV \\n\" ); stdout.flush()\n",
    "            if pts >= hmax: pts = hmax-1; stdout.write( \" ! number of points asked for the slope calculation exceeds the number of lags ! \\n\" ); stdout.flush()\n",
    "            if pts < 2: pts = 2; stdout.write( \" ! a slope cannot be calculated with a single point ! \\n\" ); stdout.flush()\n",
    "            stdout.write( \" %i points for the slope calculation \\n\" %(pts) ); stdout.flush()\n",
    "            ISV, Nugget, r, p, std_err = scipy.stats.linregress( np.log10( hs[:pts] ), np.log10 (sv[:pts] ) )\n",
    "            ISV = round(ISV,3)\n",
    "            ISVs[j,k] = ISV\n",
    "            rs[j,k] = r\n",
    "            stdout.write( \" -> Initial slope of the variogram = %0.3f\\n\" %(ISV) ); stdout.flush()\n",
    "            stdout.write( \" -> Goodness of fit of the slope = %0.3f\\n\" %(r**2) ); stdout.flush()\n",
    "\n",
    "        else: continue;\n",
    "        \n",
    "df = pd.DataFrame({'Patients': p,'ISV L1': ISVs[0,:], 'ISV L2': ISVs[1,:], 'ISV L3': ISVs[2,:], 'ISV L4': ISVs[3,:], 'Goodness of fit (R) L1': rs[0,:], 'Goodness of fit (R) L2': rs[1,:], 'Goodness of fit (R) L3': rs[2,:], 'Goodness of fit (R) L4': rs[3,:]})\n",
    "df.to_excel(out_path + \"profile_ISV_features.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
